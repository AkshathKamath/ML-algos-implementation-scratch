{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d-pAaiBWWQsy"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### X is a NxM matrix and Y is a Nx1 matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmPQmn0vWUXZ",
        "outputId": "d5837b3c-c95e-4c22-d72f-5c363cddfb15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.  0.  0. ]\n",
            " [0.  1.  1. ]\n",
            " [1.  0.  1. ]\n",
            " [1.  1.  1. ]\n",
            " [0.5 0.5 0.5]\n",
            " [0.8 0.2 0.3]]\n",
            "\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[0, 0, 0],\n",
        "              [0, 1, 1],\n",
        "              [1, 0, 1],\n",
        "              [1, 1, 1],\n",
        "              [0.5, 0.5, 0.5],\n",
        "              [0.8, 0.2, 0.3]])\n",
        "\n",
        "Y = np.array([[0],\n",
        "              [0],\n",
        "              [0],\n",
        "              [1],\n",
        "              [0],\n",
        "              [1]])\n",
        "print(X)\n",
        "print(\"\")\n",
        "print(Y) ## Nx1 matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IIjYouTayC1"
      },
      "source": [
        "#### Implementation of Logistic Regression with maximizing log likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### We add the column of X0 where all X0s are 1s to X so that the matrix multiplication in the next steps becomes easier. This makes X a NxM+1 matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OblS-6WCWYFy",
        "outputId": "7967104c-993d-441b-d811-56e2fb7f0d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1. , 0. , 0. , 0. ],\n",
              "       [1. , 0. , 1. , 1. ],\n",
              "       [1. , 1. , 0. , 1. ],\n",
              "       [1. , 1. , 1. , 1. ],\n",
              "       [1. , 0.5, 0.5, 0.5],\n",
              "       [1. , 0.8, 0.2, 0.3]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Adding X0 column of ones\n",
        "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "X ## NxM matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### We set our initial learning rate. We can play around with this rate, to control the amount of gradient descent has effect on params. Larger rate makes the descent rapid but can cause cost to sway other way, where as smaller rate can cause the gradient descent steps to have very less effect.\n",
        "###### We set the number of iterations as well. Can play around till the cost is minimized after a point.\n",
        "###### Updated m = M+1 and n = N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S3uHyUGYXb0W"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "n_iterations = 1000\n",
        "m = X.shape[1] ##No. of features\n",
        "n = X.shape[0] ##No. of training samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Setting the initial params values. Can set all to 0 as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENxduTJ9X-X2",
        "outputId": "2f7a61f1-432f-46d8-9255-bf4e6cec2b9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Initialize random weights\n",
        "weights = np.random.rand(m, 1)\n",
        "weights.shape ## Mx1 matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Setting up our logistic function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DHjwostUdVLw"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Batch Gradient ascent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXXGp6s_YV9U",
        "outputId": "df3e58e1-e965-4013-87b6-6f268f84fd10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.27836175],\n",
              "       [ 0.36026302],\n",
              "       [-0.0531296 ],\n",
              "       [-0.38798215]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for _ in range(n_iterations):\n",
        "  ## Batch Grad ascent\n",
        "  weights = weights + learning_rate * (X.T @ (Y - (sigmoid(X @ weights)))) ## theta = theta + alpha*((y - predicition) * X)\n",
        "weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### The predictions given by multiplying the X and params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AuR7AMFaFAL",
        "outputId": "af71e15b-5a39-4191-a887-05d4d127eb5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.27836175],\n",
              "       [-0.71947351],\n",
              "       [-0.30608088],\n",
              "       [-0.35921049],\n",
              "       [-0.31878612],\n",
              "       [-0.1171719 ]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = X @ weights\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Creating decision boundary where at 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS2VSQfTd8Kv",
        "outputId": "52db55fa-0dcc-40a4-ad2b-e3a376a8639a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = (predictions >= 0.5).astype(int)\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
