{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d-pAaiBWWQsy"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmPQmn0vWUXZ",
        "outputId": "943b556b-20cd-4581-ccfe-5b14e990ad34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [2 3 4]\n",
            " [3 4 5]\n",
            " [4 5 6]\n",
            " [5 6 7]]\n",
            "[[ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [ 9]\n",
            " [10]]\n"
          ]
        }
      ],
      "source": [
        "## N training examples\n",
        "## M features\n",
        "\n",
        "X = np.array([[1, 2, 3],\n",
        "              [2, 3, 4],\n",
        "              [3, 4, 5],\n",
        "              [4, 5, 6],\n",
        "              [5, 6, 7]])\n",
        "\n",
        "Y = Y = np.array([[6],\n",
        "              [7],\n",
        "              [8],\n",
        "              [9],\n",
        "              [10]])\n",
        "print(X)\n",
        "print(Y) ## Nx1 matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### X is a NxM matrix and Y is a Nx1 matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IIjYouTayC1"
      },
      "source": [
        "#### Implementation of Linear Regression with minimizing Least Square error cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### We add the column of X0 where all X0s are 1s to X so that the matrix multiplication in the next steps becomes easier. This makes X a NxM+1 matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OblS-6WCWYFy",
        "outputId": "0d4da499-009d-4a1f-9745-1035d9bb6385"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1., 2., 3.],\n",
              "       [1., 2., 3., 4.],\n",
              "       [1., 3., 4., 5.],\n",
              "       [1., 4., 5., 6.],\n",
              "       [1., 5., 6., 7.]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "X "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### We set our initial learning rate. We can play around with this rate, to control the amount of gradient descent has effect on params. Larger rate makes the descent rapid but can cause cost to sway other way, where as smaller rate can cause the gradient descent steps to have very less effect.\n",
        "###### We set the number of iterations as well. Can play around till the cost is minimized after a point.\n",
        "###### Updated m = M+1 and n = N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S3uHyUGYXb0W"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.005\n",
        "n_iterations = 1000\n",
        "m = X.shape[1] \n",
        "n = X.shape[0] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Setting the initial params values. Can set all to 0 as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENxduTJ9X-X2",
        "outputId": "6b881a63-6578-4725-95b3-ad05d1853d43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Initialize random weights\n",
        "weights = np.random.rand(m, 1)\n",
        "weights.shape ## Mx1 matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l9eJM0u0ZPR"
      },
      "source": [
        "#### Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### Running batch gradient descent where the cost is computed for all the examples first and then the params are updated by multiplying with the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXXGp6s_YV9U",
        "outputId": "ac3083f8-3e65-4f60-dc4f-2e783b52cd27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.83259682],\n",
              "       [-0.81277905],\n",
              "       [ 0.45974968],\n",
              "       [ 1.35332073]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for _ in range(n_iterations):\n",
        "  ## Batch grad descent\n",
        "  weights = weights -  learning_rate * (X.T @ ((X @ weights) - Y)) ## theta = theta - alpha*((prediction - y) * X)\n",
        "weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### The predictions given by multiplying the X and params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AuR7AMFaFAL",
        "outputId": "a3c77acd-dd61-417c-b826-fc3d728501a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 5.99927932],\n",
              "       [ 6.99957067],\n",
              "       [ 7.99986203],\n",
              "       [ 9.00015339],\n",
              "       [10.00044475]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = X @ weights\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq9RRChu0Uaq"
      },
      "source": [
        "#### Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlMF4F8WxqmF",
        "outputId": "6112c611-b928-4f8b-8613-a7b49598a3f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights = np.random.rand(m, 1)\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdZHXtiDx9Cd",
        "outputId": "e726933a-1cbb-4e44-e3af-72d7c9f0c9d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.62776816],\n",
              "       [-0.7983339 ],\n",
              "       [ 0.22499107],\n",
              "       [ 1.57343173]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for _ in range(n_iterations):\n",
        "  for i in range(n):\n",
        "    weights = weights -  learning_rate * (X[i].reshape(m, 1) @ ((X[i].reshape(1, m) @ weights) - Y[i].reshape(1, 1)))\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCAXUt4Byu4H",
        "outputId": "902701ac-62c7-41c4-bc64-a11841875b3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 5.99971157],\n",
              "       [ 6.99980046],\n",
              "       [ 7.99988935],\n",
              "       [ 8.99997824],\n",
              "       [10.00006713]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = X @ weights\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
